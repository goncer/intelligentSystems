---
title: "Gonzalo Del Cerro Morera - Annotation - 1"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Corpus annotation

In the following section we are going to see how the text is analized and check what is the result of the syntactical analysis. 
```{r Corpus annotations script}

getwd()
setwd("/home/gonzo/workspace/R/intelligent/intelligentSystems/unit2")

##load libraries.
library(rJava)
.jinit(parameters="-Xmx4g")
# If there are more memory problems, invoke gc() after the POS tagging

library(openNLP) 
####Install required library.
#install.packages("http://datacube.wu.ac.at/src/contrib/openNLPmodels.en_1.5-1.tar.gz",repos=NULL, type="source")
library(openNLPmodels.en)
library(tm)

##Functions
getAnnotationsFromDocument = function(doc){
  x=as.String(doc)
  sent_token_annotator <- Maxent_Sent_Token_Annotator()
  word_token_annotator <- Maxent_Word_Token_Annotator()
  pos_tag_annotator <- Maxent_POS_Tag_Annotator()
  y1 <- annotate(x, list(sent_token_annotator, word_token_annotator))
  y2 <- annotate(x, pos_tag_annotator, y1)
  parse_annotator <- Parse_Annotator()
  y3 <- annotate(x, parse_annotator, y2)
  return(y3)  
} 

getAnnotatedMergedDocument = function(doc,annotations){
  x=as.String(doc)
  y2w <- subset(annotations, type == "word")
  tags <- sapply(y2w$features, '[[', "POS")
  r1 <- sprintf("%s/%s", x[y2w], tags)
  r2 <- paste(r1, collapse = " ")
  return(r2)  
} 

getAnnotatedPlainTextDocument = function(doc,annotations){
  x=as.String(doc)
  a = AnnotatedPlainTextDocument(x,annotations)
  return(a)  
}

##Filter the files to load with a RegEx. Only  GET: CERRO MORERA GONZALO DEL  : cv420_* - cv429_*
source.pos = DirSource("/home/gonzo/workspace/R/intelligent/intelligentSystems/unit2/txt_sentoken/pos",
                       encoding = "UTF-8", pattern="(cv42[0-9]_[0-9]+.\\w*)")
corpus = Corpus(source.pos)
annotations = lapply(corpus, getAnnotationsFromDocument)

corpus.tagged = Map(getAnnotatedPlainTextDocument, corpus, annotations)
corpus.taggedText = Map(getAnnotatedMergedDocument, corpus, annotations)

#Geet the first document
doc = corpus.tagged[[1]] 
#as.character(doc)
#head(words(doc))
sentences = 2
head(sents(doc),sentences)
#head(tagged_words(doc))
head(tagged_sents(doc),sentences)
##head(parsed_sents(doc),sentences)

```

## POS tagging evaluation

Evaluation of the manual results are:
###Errors found in :
```{r conclusion first}
head(tagged_sents(doc),2)[1]

```
* square/JJ should be a /NN . Its part of the company name.
* final/JJ should be a /NN . Its the name of the film. 
* groundbreaking/NN should be a /JJ. Its an Ajd.

```{r conclusion sec}
head(tagged_sents(doc),2)[2]
```
* deserved/VBN is a JJ, Is telling us how is the release.

## Conclusion

**From 62 words, the algorithm seems to be failed in 4 False positives.** 

```{r pressure, echo=FALSE}

slices <- c(58 ,4)
lbls <- c("True positive ", "False Positive")
pct <- round(slices/sum(slices)*100)
lbls <- paste(lbls, pct) # add percents to labels
lbls <- paste(lbls,"%",sep="") # ad % to labels 
pie(slices, labels = lbls, main="Pie Chart of Countries")

```

##With a precision of: 
```{r conclusion tree}
precision = 58 / (58 + 4) 
precision
```
